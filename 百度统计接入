//埋点统计的神马的，有现成的工具当然要用的哇。



百度统计就很不错，直接埋下去一段js就有了哇卡卡卡。

但是网站内的数据需要这一部分，自然就要去看看怎么调用他的API拿到这一部分数据了阿。
于是面向搜索引擎编程开始了。
拿了他的JAVA的Demo居然跑不起来，不知道是IDE的锅还是我的锅，多半是我的，这个问题需要问问大神。

然后就继续搜阿，就看到了一段Python的访问代码，一看他用的库 urllib.request ...撸过爬虫的第一反应是，卧槽，我觉得这个是可以用request包改写的，
然后他的源代码是这样的https://www.cnblogs.com/w1570631036/p/7096966.html?utm_source=debugrun&utm_medium=referral

import urllib.request
import urllib.parse
import json
import time
import datetime

start_date = time.strftime("%Y%m%d", time.localtime())
today = datetime.date.today()
yesterday = today - datetime.timedelta(days=1)
fifteenago = today - datetime.timedelta(days=7)
end, start = str(yesterday).replace("-", ""), str(fifteenago).replace("-", "")
base_url = "https://api.baidu.com/json/tongji/v1/ReportService/getData"
body = {"header": {"account_type": 1, "password": "", "token": "",
                   "username": ""},
        "body": {"siteId": , "method": "visit/district/a", "start_date": start, "end_date": end,
                 "metrics": "pv_count,visitor_count,avg_visit_time"}} 
data = bytes(json.dumps(body), 'utf8')
req = urllib.request.Request(base_url, data)
response = urllib.request.urlopen(req)
the_page = response.read()
result=json.loads(the_page.decode("utf-8"))
base=result["body"]["data"][0]["result"]["items"]
source=[]
for item in base[0]:
    source.append(item[0]['name'])
count=0
detail=[]
for item in base[1]:
    tojson={}
    tojson['name']=source[count]
    tojson['pv_count']=item[0]
    tojson['pv_ratio']=item[1]
    tojson['visitor_count']=item[2]
    count=count+1
    detail.append(tojson)
    
看了一下，其实就是构造了一个请求头，然后post~~~~~~~~~~~~~过去就返回值了。
然后就用request重新写了一下这个，就成了这个样子:



之后想着，这样的话PHP应该也就是这样，然后去查php用来构造访问请求的包，然后就找到了curl，这时候一搜。
我的天，原来百度统计也是有Php的源代码的哇，那就不用自己去构造了。是长这个样纸的:

突然发现，哇咔咔，有php源代码诶。是这个样子的，然后就对照百度的API手册。http://tongji.baidu.com/dataapi/file/TongjiApiFile.pdf
拿自己的数据了的哇。
